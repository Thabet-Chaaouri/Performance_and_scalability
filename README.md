# Performance_and_scalability

### Optimizing inference

Use a GPU, and optimize inference with:

- Flash-attention :
- BetterTransformer :
- Quantization with bitsandbytes :
